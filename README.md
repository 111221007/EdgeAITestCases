# EdgeAITestCases
# Edge AI Deployment

**Efficient Edge AI Model Deployment for Real-Time Inference**  
*A focus on latency reduction in autonomous systems and smart IoT applications*

---

## ğŸš€ Project Overview

This repository provides a modular Python framework for training, evaluating, and running inference on multiple lightweight Edge AI models:

- **Image Segmentation** (e.g. U-Net, FastSCNN, BiSeNet, ENet, LEDNet)  
- **Object Detection** (e.g. YOLOv5-Nano, SSD-Lite, EfficientDet-Lite0, MobileNet-SSD, NanoDet)

Each task lives in its own module (`image_segmentation/` and `object_detection/`), with clear separation of:

- `models/` â€” model definitions  
- `scripts/` â€” training / evaluation / inference entrypoints  
- `data/` â€” dataset storage  

A unified `main.py` lets you launch any module in **train**, **eval**, or **infer** mode.

---

## ğŸ“ Repository Structure

```text
edge_ai_deployment/
â”œâ”€â”€ README.md              â† this file
â”œâ”€â”€ requirements.txt       â† Python dependencies
â”œâ”€â”€ main.py                â† CLI entrypoint
â”‚
â”œâ”€â”€ image_segmentation/    â† Image-segmentation module
â”‚   â”œâ”€â”€ models/            â† model architectures
â”‚   â”‚   â”œâ”€â”€ unet.py
â”‚   â”‚   â”œâ”€â”€ fast_scnn.py
â”‚   â”‚   â”œâ”€â”€ bisenet.py
â”‚   â”‚   â”œâ”€â”€ enet.py
â”‚   â”‚   â””â”€â”€ lednet.py
â”‚   â”œâ”€â”€ scripts/           â† training / evaluation / inference
â”‚   â”‚   â”œâ”€â”€ train.py
â”‚   â”‚   â”œâ”€â”€ evaluate.py
â”‚   â”‚   â””â”€â”€ infer.py
â”‚   â””â”€â”€ data/              â† datasets (e.g. CamVid, Cityscapes)
â”‚       â”œâ”€â”€ camvid/
â”‚       â””â”€â”€ cityscapes/
â”‚
â””â”€â”€ object_detection/      â† Object-detection module
    â”œâ”€â”€ models/            â† model architectures
    â”‚   â”œâ”€â”€ yolov5_nano.py
    â”‚   â”œâ”€â”€ ssd_lite.py
    â”‚   â”œâ”€â”€ efficientdet_lite0.py
    â”‚   â”œâ”€â”€ mobilenet_ssd.py
    â”‚   â””â”€â”€ nanodet.py
    â”œâ”€â”€ scripts/           â† training / evaluation / inference
    â”‚   â”œâ”€â”€ train.py
    â”‚   â”œâ”€â”€ evaluate.py
    â”‚   â””â”€â”€ infer.py
    â””â”€â”€ data/              â† datasets (e.g. Pascal VOC, COCO subset)
        â”œâ”€â”€ voc/
        â””â”€â”€ coco_subset/
```

---

## âš™ï¸ Installation

1. **Clone this repo**  
   ```bash
   git clone https://github.com/your-username/edge_ai_deployment.git
   cd edge_ai_deployment
   ```

2. **Create & activate a virtual environment**  
   ```bash
   python3 -m venv venv
   source venv/bin/activate    # on Windows use `venv\\Scripts\\activate`
   ```

3. **Install dependencies**  
   ```bash
   pip install -r requirements.txt
   ```

4. **Prepare your data**  
   - Download & extract your datasets under the appropriate `*/data/` folders.  
   - Ensure train/val/test splits exist as expected by the dataset loaders in each module.

---

## â–¶ï¸ Usage

All commands invoke `main.py`:

```bash
python main.py <task> <mode>
```

- `<task>`:  
  - `seg` â€” image segmentation  
  - `det` â€” object detection  

- `<mode>`:  
  - `train` â€” train the model  
  - `eval`  â€” evaluate on validation/test set  
  - `infer` â€” run inference on sample images or video  

### Examples

- **Train segmentation** with U-Net on CamVid:  
  ```bash
  python main.py seg train
  ```

- **Evaluate detection** on VOC:  
  ```bash
  python main.py det eval
  ```

- **Inference** with YOLOv5-Nano on a sample video:  
  ```bash
  python main.py det infer --source path/to/video.mp4
  ```

---

## ğŸ› ï¸ Extending & Customizing

- **Add new models**  
  - Create a new `*.py` in `models/` defining a `nn.Module` class.  
  - Register your model in the corresponding `scripts/train.py` loader.

- **Implement new datasets**  
  - Under `data/`, add a custom `Dataset` class for loading images & labels.  
  - Update `scripts/train.py` to import & instantiate your dataset.

- **Export & Optimize**  
  - Inside each `scripts/`, you can add export routines to ONNX or TensorRT.  
  - Insert post-training quantization or pruning workflows as needed.

- **Logging & Metrics**  
  - Integrate TensorBoard / Weights & Biases in `scripts/train.py` and `evaluate.py`.  
  - Compute mIoU for segmentation and mAP for detection.

---

## ğŸ“š References

- **Segmentation Architectures**:  
  - U-Net, FastSCNN, BiSeNet, ENet, LEDNet  
- **Detection Architectures**:  
  - YOLOv5-Nano, SSD-Lite, EfficientDet-Lite0, MobileNet-SSD, NanoDet  
- **Datasets**:  
  - [CamVid](https://github.com/alexgkendall/SegNet-Tutorial)  
  - [Cityscapes](https://www.cityscapes-dataset.com/)  
  - [Pascal VOC](http://host.robots.ox.ac.uk/pascal/VOC/)  
  - [COCO](https://cocodataset.org/)

---

## ğŸ¤ Contributing

1. Fork this repository  
2. Create your feature branch (`git checkout -b feature/YourFeature`)  
3. Commit your changes (`git commit -m "Add YourFeature"`)  
4. Push to the branch (`git push origin feature/YourFeature`)  
5. Open a Pull Request

---

## ğŸ“„ License

This project is licensed under the MIT License. See the [LICENSE](LICENSE) file for details.

